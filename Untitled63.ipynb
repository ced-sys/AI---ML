{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPW28hgfpUxugrcCJkuI8q0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ced-sys/AI---ML/blob/main/Untitled63.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "M9nhImkvUfew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMuZahP8Md_5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CroplandMapper:\n",
        "  def __init__(Self, data_path):\n",
        "    self.data_path=data_path\n",
        "    self.models={}\n",
        "    self.scaler={}\n",
        "    self.feature_names=[]\n",
        "    self.best_model=None\n",
        "\n",
        "  def load_data(self):\n",
        "    print(\"Loading data files...\")\n",
        "\n",
        "    try:\n",
        "      self.train_fergana=gpd.read_file(f\"{self.data_path}/Train/fergana_train.shp\")\n",
        "      self.train_orenburg-gpd.read_file(f\"{self.data_path}/Train/orenburg_train.shp\")\n",
        "      print(f\"Loaded Fergana training data: {len(self.train_fergana)} samples\")\n",
        "      print(f\"Loaded Orenburg training data: {len(self.train_orenburg)} samples\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading shapefiles: {e}\")\n",
        "      try:\n",
        "        import os\n",
        "        train_files=os.listdir(f\"{self.data_path}/Train\")\n",
        "        shp_files=[f for f in train_files if f.endswith('.shp')]\n",
        "        print(f\"Found shapefiles: {shp_files}\")\n",
        "\n",
        "        if len(sh_files)>=2:\n",
        "          self.train_fergana=gpd.read_file(f\"{self.data_path}/Train/{shp_files[0]}\")\n",
        "          self.train_orenburg=gpd.read_file(f\"{self.data_path}/Train/{shp_files[1]}\")\n",
        "          print(f\"Loaded trainin data successfully\")\n",
        "\n",
        "      except Exception as e2:\n",
        "        print(f\"Failed to load shapefiles: {e2}\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "\n",
        "      self.sentinel1_data=pd.read_csv(f\"{self.data_path}/Sentinel1.csv\")\n",
        "      self.sentinel2_data=pd.read_csv(f\"{self.data_path}/Sentinel2.csv\")\n",
        "      self.test_data=pd.read_csv(f\"{self.data_path}/Test.csv\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading CSV files: {e}\")\n",
        "      return False\n",
        "\n",
        "    return True\n",
        "\n",
        "  def explore_data(self):\n",
        "    self.combined_train=pd.concat([\n",
        "        self.train_fergana.drop('geometry', axis=1),\n",
        "        self.train_orenburg.drop('geometry', axis=1)\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    print(f\"\\nCombined training data shape: {self.combined_train.shape}\")\n",
        "    print(f\"\\nColumns in training data: {list(self.combined_train.columns)}\")\n",
        "\n",
        "    if 'Target' in self.combined_train.columns:\n",
        "      target_dist=self.combined_train['Target'].value_counts()\n",
        "      print(f\"\\nTarget distribution:\")\n",
        "      print(f\"Cropland (1): {target_dist.get(1, 0)} ({target_dist.get(1, 0)/len(self.combined_train)*100:.1f}%)\")\n",
        "      print(f\"Non-cropland (0): {target_dist.get(0, 0)} ({target_dist.get(0, 0)/len(self.combined_train)*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nSentinale-1 columns: {list(self.sentinel1_data.columns)}\")\n",
        "    print(f\"Sentinel-2 columns: {list(self.sentinel2_data.columns)}\")\n",
        "\n",
        "    print(f\"\\nMissing values in Sentinel-1: {self.sentinel1_data.isnull().sum().sum()}\")\n",
        "    print(f\"\\nMissing values in Sentinel-2: {self.sentinel2_data.isnull().sum().sum()}\")\n",
        "\n",
        "    return self.combined_train\n",
        "\n",
        "  def create_features(self):\n",
        "    merged_data=pd.merge(self.sentinel1_data, self.sentinel2_data, on='ID', how='outer')\n",
        "    print(f\"Merged satellite data shape: {merged_data.shape}\")\n",
        "\n",
        "    for col in merged_data.columns:\n",
        "      if col!=\"ID\" and merged_data[col].dtype in ['float64', 'int64']:\n",
        "        merged_data[col]=merged_data[col].fillna(merged_data[col].median())\n",
        "\n",
        "        self.features_df=merged_data.cppy()\n",
        "\n",
        "        s1_bands=[col for col in merged_data.columns if 'VV' in col or' VH' in col]\n",
        "        s2_bands=[col for col in merged_data.columns if any (b in col for b in ['B02', 'B03', 'B04', 'B08', 'B11', 'B11'])]\n",
        "\n",
        "        print(f\"Sentinel-1bands found: {len(s1_bands)}\")\n",
        "        print(f\"Sentinel-2 bands found: {len(s2_bands)}\")\n",
        "\n",
        "        for band_group, band_name in [(s1_bands, 'S1'), (s2_bands, 'S2')]:\n",
        "          if band_group:\n",
        "            band_data=merged_data[band_group]\n",
        "\n",
        "            self.features_df[f'{band_name}_mean']=band_data.mean(axis=1)\n",
        "            self.features_df[f'{band_name}_std']=band_data.std(axis=1)\n",
        "            self.features_df[f'{band_name}_min']=band_data.min(axis=1)\n",
        "            self.features_df[f'{band_name}_max']=band_data.max(axis=1)\n",
        "            self.features_df[f'{band_name}_range']=self.features_df[f'{band_name}_max']-self.features_df[f'{band_name}_min']\n",
        "            self.features_df[f'{band_name}_cv']=self.features_df[f'{band_name}_std']/ (self.features_df[f'{band_name}_mean']+1e-8)\n",
        "\n",
        "            for i, row in badn_data.iterrows():\n",
        "              values=row.dropna().vaues\n",
        "              if len(values)>1:\n",
        "                trend=np.polyfit(range(len(values)), values, 1)[0]\n",
        "                self.features_df.loc[i, f'{band_name}_trend']=trend\n",
        "              else:\n",
        "                self.features_dfloc[i, f'{band_name}_trend']=0\n",
        "\n",
        "\n",
        "                nir_cols=[col for col in s2_bands if 'B08' in col]\n",
        "                red_cols=[col for col i s2_bands if 'B04' in col]\n",
        "\n",
        "                if nir_cols and red_cols:\n",
        "                  for nir_col, red_col in zip(nir_cols, red_cols):\n",
        "                    date_suffix=nir_col.split('_')[-1] if '_' in nir_col else ''\n",
        "                    ndvi_col=f'NDVI_{date_suffix}' if date_suffix else f'NDVI_{nir_col[-8:]}'\n",
        "\n",
        "                    nir_vals=merged_data[nir_col]\n",
        "                    red_vals=merged_data[red_col]\n",
        "                    self.features_df[ndvi_col]=(nir_vals-red_vals)/(nir_vals+red_vals+1e-8)\n",
        "\n",
        "                    ndvi_cols=[col for col in self.features_df.columns if 'NDVI' in col]\n",
        "                    if ndvi_cols:\n",
        "                      ndvi_data=self.features_df[ndvi_cols]\n",
        "                      self.features_df['NDVI_mean']=ndvi_data.mean(axis=1)\n",
        "                      self.features_df['NDVI_std']=ndvi_data.std(axis=1)\n",
        "                      self.features_df['NDVI_min']=ndvi_data.min(axis=1)\n",
        "                      self.features_df['NDVI_max']=ndvi_data.max(axis=1)\n",
        "                      self.features_df['NDVI_range']=self.features_df['NDVI_max']-self.features_df['NDVI_min']\n",
        "\n",
        "                if s1_bands:\n",
        "                  VV_cols=[col for col in s1_bands if 'VV' in col]\n",
        "                  vh_cols=[col for col in s1_bands if 'VH' in col]\n",
        "\n",
        "                  if vv_cols and vh_cols:\n",
        "                    for vv_cols, vh_col in zip(vv_cols, vh_cols):\n",
        "                      date_suffix=vv_col.split('_')[-1]if '_' in vv_col else ''\n",
        "                      ratio_col=f'VV_VH_ratio_{date_suffix}' if date_suffix else f'VV_VH_ratio_{vv_col[-8:]}'\n",
        "\n",
        "                      vv_vals=merged_data[vv_col]\n",
        "                      vh_vals=merged_data[vh_col]\n",
        "                      self.features-df[ratio_col]=vv_vals/(vh_vals+1e-8)\n",
        "\n",
        "      print(f\"Total features created: {len(self.feature_df.columns)}\")\n",
        "      return self.features_df\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N7GvBPqXTGDT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}